{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datsets\n",
    "\n",
    "Este código finaliza la preparación de los datos antes de entrenar el modelo. Sus tareas principales son:\n",
    "\n",
    "Instalar librerías: Asegura que todas las herramientas de software necesarias estén listas.\n",
    "\n",
    "Cargar datos: Importa los conjuntos de entrenamiento, validación y prueba.\n",
    "\n",
    "Unificar etiquetas: Consolida las múltiples columnas de categorías en una sola lista de etiquetas por cada artículo.\n",
    "\n",
    "Formatear para IA: Convierte los datos al formato especializado que el modelo requiere para procesarlos eficientemente.\n",
    "\n",
    "Verificar: Confirma que todos los registros se hayan cargado correctamente en cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-08-25T05:47:05.466Z",
     "iopub.execute_input": "2025-08-25T05:46:58.562935Z",
     "iopub.status.busy": "2025-08-25T05:46:58.562641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 1: CARGA DE DATASETS (TRAIN / VAL / TEST) DESDE CSV\n",
    "# ==============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "print(\"Instalando librerías necesarias...\")\n",
    "# !pip install --upgrade transformers datasets scikit-learn -q\n",
    "print(\"¡Instalación completa!\")\n",
    "\n",
    "# Rutas a tus CSV ya separados\n",
    "TRAIN_PATH = \"/kaggle/input/split-dataset/train_set_expanded.csv\"\n",
    "VAL_PATH   = \"/kaggle/input/split-dataset/val_set.csv\"\n",
    "TEST_PATH  = \"/kaggle/input/split-dataset/test_set.csv\"\n",
    "\n",
    "TEXT_COLUMN = \"text\"\n",
    "LABEL_COLUMNS = [\"cardiovascular\", \"hepatorenal\", \"neurological\", \"oncological\"]\n",
    "\n",
    "def load_split(path):\n",
    "    df = pd.read_csv(path)\n",
    "    # Asegura tipos 0/1 en las etiquetas\n",
    "    for c in LABEL_COLUMNS:\n",
    "        df[c] = df[c].astype(int)\n",
    "    df[\"labels\"] = df[LABEL_COLUMNS].values.tolist()\n",
    "    return df[[TEXT_COLUMN, \"labels\"]].copy()\n",
    "\n",
    "try:\n",
    "    train_df = load_split(TRAIN_PATH)\n",
    "    val_df   = load_split(VAL_PATH)\n",
    "    test_df  = load_split(TEST_PATH)\n",
    "    print(\"✅ Datasets cargados correctamente.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ No se encontró un archivo: {e}\")\n",
    "    raise\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset   = Dataset.from_pandas(val_df)\n",
    "test_dataset  = Dataset.from_pandas(test_df)\n",
    "\n",
    "print(f\"Tamaño train: {len(train_dataset)}\")\n",
    "print(f\"Tamaño val:   {len(val_dataset)}\")\n",
    "print(f\"Tamaño test:  {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizacion\n",
    "\n",
    "Este script prepara un modelo SciBERT para una tarea de clasificación multietiqueta.\n",
    "\n",
    "Primero, tokeniza los datasets de texto, convirtiéndolos en tensores numéricos de longitud fija para PyTorch.\n",
    "\n",
    "Luego, instancia el modelo SciBERT y lo configura explícitamente para multi_label_classification, lo que ajusta su arquitectura para predecir múltiples categorías simultáneamente.\n",
    "\n",
    "Finalmente, define una función para evaluar el rendimiento del modelo utilizando métricas clave como F1-score y ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 2: TOKENIZACIÓN, MODELO (SCIBERT UNCASED) Y MÉTRICAS\n",
    "# ==============================================================================\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# Nombre del modelo (SciBERT uncased)\n",
    "MODEL_NAME = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "# Se asume que LABEL_COLUMNS, train_dataset, val_dataset, test_dataset\n",
    "# ya fueron creados en la Celda 1.\n",
    "id2label = {i: l for i, l in enumerate(LABEL_COLUMNS)}\n",
    "label2id = {l: i for i, l in enumerate(LABEL_COLUMNS)}\n",
    "\n",
    "# Tokenizador\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    enc = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    # Etiquetas como float32 para BCEWithLogits\n",
    "    enc[\"labels\"] = [np.array(x, dtype=np.float32) for x in batch[\"labels\"]]\n",
    "    return enc\n",
    "\n",
    "# Tokenización de los splits\n",
    "train_enc = train_dataset.map(tokenize_batch, batched=True, remove_columns=train_dataset.column_names)\n",
    "val_enc   = val_dataset.map(tokenize_batch,   batched=True, remove_columns=val_dataset.column_names)\n",
    "test_enc  = test_dataset.map(tokenize_batch,  batched=True, remove_columns=test_dataset.column_names)\n",
    "\n",
    "# Formato PyTorch\n",
    "cols = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "train_enc = train_enc.with_format(\"torch\", columns=cols)\n",
    "val_enc   = val_enc.with_format(\"torch\",   columns=cols)\n",
    "test_enc  = test_enc.with_format(\"torch\",  columns=cols)\n",
    "\n",
    "# Modelo de clasificación multilabel\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(LABEL_COLUMNS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Métricas (incluye F1 ponderado)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))          # sigmoid\n",
    "    preds = (probs >= 0.5).astype(int)         # umbral base 0.5\n",
    "\n",
    "    f1_micro = f1_score(labels, preds, average=\"micro\", zero_division=0)\n",
    "    f1_macro = f1_score(labels, preds, average=\"macro\", zero_division=0)\n",
    "    f1_weighted = f1_score(labels, preds, average=\"weighted\", zero_division=0)\n",
    "    try:\n",
    "        auc_macro = roc_auc_score(labels, probs, average=\"macro\")\n",
    "    except ValueError:\n",
    "        auc_macro = float(\"nan\")\n",
    "\n",
    "    return {\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_weighted\": f1_weighted,\n",
    "        \"roc_auc_macro\": auc_macro\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entrenamiento y  selección de mejores hiperparámetros\n",
    "\n",
    "Este script ejecuta un proceso avanzado y automatizado de optimización de hiperparámetros (HPO) utilizando la librería Optuna para encontrar la configuración de entrenamiento óptima para el modelo SciBERT. El proceso no solo busca los mejores hiperparámetros, sino que también implementa técnicas sofisticadas para manejar el desequilibrio de clases y optimizar los umbrales de decisión. Finalmente, evalúa rigurosamente el modelo campeón en el conjunto de datos de prueba y lo empaqueta para su uso futuro.\n",
    "\n",
    "Desglose Funcional Detallado\n",
    "Optimización de Hiperparámetros (HPO) con Optuna:\n",
    "\n",
    "El núcleo del script es un bucle de optimización (study.optimize) que prueba sistemáticamente múltiples combinaciones de hiperparámetros clave (tasa de aprendizaje, tamaño de lote, decaimiento de peso, etc.) para encontrar la que maximiza el rendimiento.\n",
    "El objetivo de cada \"trial\" (prueba) es maximizar la métrica f1_weighted en el conjunto de validación, que es una métrica robusta para problemas con desequilibrio de clases.\n",
    "Manejo del Desequilibrio de Clases:\n",
    "\n",
    "Se implementa una función de pérdida personalizada (compute_loss_with_pos_weight). Antes de entrenar, se calcula la frecuencia de cada etiqueta en el dataset de entrenamiento.\n",
    "La función de pérdida (BCEWithLogitsLoss) utiliza estos cálculos para asignar un mayor peso a las clases minoritarias, forzando al modelo a prestarles más atención y evitando que se centre únicamente en las clases más comunes.\n",
    "Ajuste de Umbrales de Decisión por Clase (tune_thresholds_per_class):\n",
    "\n",
    "En la clasificación multietiqueta, un umbral de decisión estándar de 0.5 no suele ser óptimo. Esta función clave se ejecuta después de cada entrenamiento de un trial.\n",
    "Para cada una de las cuatro etiquetas, busca iterativamente el umbral de probabilidad (entre 0.05 y 0.95) que maximiza el F1-score individual para esa clase en el conjunto de validación.\n",
    "El rendimiento final de un trial se mide después de aplicar estos umbrales optimizados, proporcionando una evaluación mucho más precisa del verdadero potencial del modelo.\n",
    "Gestión Eficiente de Recursos:\n",
    "\n",
    "Early Stopping: Se detienen los entrenamientos de trials que no muestran mejora después de una época, ahorrando tiempo computacional.\n",
    "Limpieza de Checkpoints (cleanup_callback): Se implementa un callback inteligente que, después de cada trial, elimina automáticamente la carpeta de checkpoints del modelo si este no supera al mejor modelo encontrado hasta el momento. Esto previene el consumo excesivo de espacio en disco, un problema común en HPO.\n",
    "Evaluación Final y Empaquetado:\n",
    "\n",
    "Una vez que Optuna completa todos los trials, identifica la mejor configuración (best_trial).\n",
    "Carga el modelo campeón desde su checkpoint guardado y utiliza los umbrales de decisión optimizados que se calcularon para ese trial.\n",
    "Realiza una evaluación final y definitiva en el conjunto de datos de prueba (test_enc), que el modelo nunca ha visto, para obtener una medida imparcial de su rendimiento en el mundo real.\n",
    "Finalmente, guarda un paquete de inferencia completo que contiene el modelo entrenado, el tokenizador y el archivo best_thresholds.json. Esto permite que el modelo sea fácilmente cargado y utilizado para hacer predicciones en el futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# CELDA 3: OPTUNA (HPO) + UMBRALES POR CLASE + EVALUACIÓN FINAL — CRITERIO: f1_weighted\n",
    "# ==============================================================================\n",
    "\n",
    "# Requiere que ya existan: MODEL_NAME, LABEL_COLUMNS, tokenizer, train_df, train_enc, val_enc, test_enc, compute_metrics\n",
    "\n",
    "# !pip install optuna -q\n",
    "\n",
    "import os\n",
    "# Desactivar integraciones que bloquean (W&B) y ruido\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "\n",
    "import gc, json, math, optuna, numpy as np, torch, shutil # <-- NUEVO: Importamos shutil para borrar carpetas\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "\n",
    "# Info de dispositivo\n",
    "print(\"CUDA disponible:\", torch.cuda.is_available(), \"| #GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU[0]:\", torch.cuda.get_device_name(0))\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "try:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# En notebook, el Trainer suele usar 1 GPU. Si usas accelerate/DDP, cambia a torch.cuda.device_count().\n",
    "n_gpus_eff = 1 if torch.cuda.is_available() else 0\n",
    "MAX_PER_DEVICE_BS = 16  # baja a 8 si hay OOM\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tune_thresholds_per_class(probs, y_true, steps=100):\n",
    "    C = probs.shape[1]\n",
    "    thresholds = []\n",
    "    for i in range(C):\n",
    "        best_f, best_th = 0.0, 0.5\n",
    "        p = probs[:, i]\n",
    "        y = y_true[:, i]\n",
    "        for th in np.linspace(0.05, 0.95, steps):\n",
    "            f = f1_score(y, (p >= th).astype(int), zero_division=0)\n",
    "            if f > best_f:\n",
    "                best_f, best_th = f, th\n",
    "        thresholds.append(best_th)\n",
    "    thresholds = np.array(thresholds)\n",
    "    preds = (probs >= thresholds).astype(int)\n",
    "    return thresholds, {\n",
    "        \"f1_macro\":     f1_score(y_true, preds, average=\"macro\",    zero_division=0),\n",
    "        \"f1_micro\":     f1_score(y_true, preds, average=\"micro\",    zero_division=0),\n",
    "        \"f1_weighted\":  f1_score(y_true, preds, average=\"weighted\", zero_division=0),\n",
    "        \"auprc_macro\":  average_precision_score(y_true, probs, average=\"macro\")\n",
    "    }\n",
    "\n",
    "def build_model():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(LABEL_COLUMNS),\n",
    "        problem_type=\"multi_label_classification\",\n",
    "        id2label={i: l for i, l in enumerate(LABEL_COLUMNS)},\n",
    "        label2id={l: i for i, l in enumerate(LABEL_COLUMNS)}\n",
    "    )\n",
    "\n",
    "# pos_weight por desbalance (train_df['labels'])\n",
    "pos_counts = np.array(train_df[\"labels\"].tolist()).sum(axis=0)\n",
    "N = len(train_df)\n",
    "pos_weight = torch.tensor((N - pos_counts) / np.clip(pos_counts, 1, None), dtype=torch.float32)\n",
    "\n",
    "def compute_loss_with_pos_weight(model, inputs, return_outputs=False,**kwargs):\n",
    "    labels = inputs.pop(\"labels\").float()\n",
    "    outputs = model(**inputs)\n",
    "    loss = BCEWithLogitsLoss(pos_weight=pos_weight.to(outputs.logits.device))(outputs.logits, labels)\n",
    "    return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def objective(trial):\n",
    "    # Espacio de búsqueda\n",
    "    learning_rate    = trial.suggest_float(\"learning_rate\", 2.5e-5, 5e-5, log=True)\n",
    "    eff_batch_size   = trial.suggest_categorical(\"effective_batch_size\", [16, 32])\n",
    "    num_train_epochs = trial.suggest_int(\"num_train_epochs\", 4, 8)\n",
    "    weight_decay     = trial.suggest_float(\"weight_decay\", 0.0, 0.1) # Mantener este rango amplio\n",
    "    warmup_ratio     = trial.suggest_float(\"warmup_ratio\", 0.0, 0.1) # Acotar un poco, rara vez se necesita más\n",
    "\n",
    "    per_device_bs = min(MAX_PER_DEVICE_BS, eff_batch_size)\n",
    "    den = max(1, per_device_bs * max(1, n_gpus_eff))\n",
    "    grad_accum = max(1, math.ceil(eff_batch_size / den))\n",
    "    print(f\"[Trial {trial.number}] per_device_bs={per_device_bs}, grad_accum={grad_accum}, eff_bs≈{per_device_bs*max(1,n_gpus_eff)*grad_accum}\")\n",
    "\n",
    "    output_dir = f\"/kaggle/working/hpo_scibert_uncased/trial_{trial.number}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Guardamos la ruta del directorio para poder acceder a ella en el callback\n",
    "    trial.set_user_attr(\"output_dir\", output_dir) # <-- NUEVO: Guardamos la ruta en los atributos del trial\n",
    "\n",
    "    model = build_model()\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_weighted\",\n",
    "        greater_is_better=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=per_device_bs,\n",
    "        per_device_eval_batch_size=max(per_device_bs, 32),\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        weight_decay=weight_decay,\n",
    "        warmup_ratio=warmup_ratio,\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        seed=42,\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        dataloader_pin_memory=True,\n",
    "        dataloader_num_workers=2, # Reducido a 2 para evitar cuellos de botella en Kaggle\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_enc,\n",
    "        eval_dataset=val_enc,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]\n",
    "    )\n",
    "    trainer.compute_loss = compute_loss_with_pos_weight\n",
    "    trainer.train()\n",
    "\n",
    "    val_out = trainer.predict(val_enc)\n",
    "    val_probs = sigmoid(val_out.predictions)\n",
    "    val_y = val_out.label_ids\n",
    "    val_thresholds, val_metrics_thr = tune_thresholds_per_class(val_probs, val_y, steps=100)\n",
    "\n",
    "    trial.set_user_attr(\"val_thresholds\", val_thresholds.tolist())\n",
    "    trial.set_user_attr(\"val_metrics_thr\", val_metrics_thr)\n",
    "\n",
    "    del trainer, model\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return val_metrics_thr[\"f1_weighted\"]\n",
    "\n",
    "# ==============================================================================\n",
    "# <-- INICIO: NUEVA SECCIÓN PARA GESTIÓN DE ALMACENAMIENTO -->\n",
    "# ==============================================================================\n",
    "\n",
    "def cleanup_callback(study: optuna.study.Study, trial: optuna.trial.FrozenTrial):\n",
    "    \"\"\"\n",
    "    Callback para limpiar los checkpoints de los trials que no son el mejor.\n",
    "    Se ejecuta después de cada trial y borra la carpeta de checkpoints si\n",
    "    el trial recién terminado no es el mejor hasta ahora.\n",
    "    \"\"\"\n",
    "    # Buscamos el directorio del mejor trial hasta el momento\n",
    "    try:\n",
    "        best_trial_dir = study.best_trial.user_attrs.get(\"output_dir\")\n",
    "    except (AttributeError, KeyError):\n",
    "        best_trial_dir = None # Aún no hay un mejor trial (p.ej. en el primer trial)\n",
    "\n",
    "    # Buscamos el directorio del trial que acaba de terminar\n",
    "    try:\n",
    "        current_trial_dir = trial.user_attrs.get(\"output_dir\")\n",
    "    except (AttributeError, KeyError):\n",
    "        current_trial_dir = None\n",
    "        \n",
    "    # Si el directorio del trial actual existe y NO es el del mejor trial, lo borramos\n",
    "    if current_trial_dir and current_trial_dir != best_trial_dir and os.path.exists(current_trial_dir):\n",
    "        print(f\"🧹 Limpiando checkpoint del trial {trial.number} (no es el mejor). Directorio: {current_trial_dir}\")\n",
    "        shutil.rmtree(current_trial_dir)\n",
    "\n",
    "# ==============================================================================\n",
    "# <-- FIN: NUEVA SECCIÓN -->\n",
    "# ==============================================================================\n",
    "\n",
    "# Ejecutar estudio\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"scibert_uncased_hpo\",\n",
    "                            pruner=optuna.pruners.MedianPruner(n_startup_trials=2))\n",
    "study.optimize(objective, n_trials=10, callbacks=[cleanup_callback]) # <-- NUEVO: Añadimos el callback\n",
    "\n",
    "print(\"\\nMejores hiperparámetros:\", study.best_params)\n",
    "print(\"Mejor F1_weighted (val, con thresholds):\", study.best_value)\n",
    "\n",
    "best_trial = study.best_trial\n",
    "best_dir = best_trial.user_attrs[\"output_dir\"]\n",
    "best_thresholds = np.array(best_trial.user_attrs[\"val_thresholds\"])\n",
    "print(\"Checkpoint del mejor trial:\", best_dir)\n",
    "print(\"Umbrales del mejor trial:\", best_thresholds)\n",
    "\n",
    "# Evaluación final en TEST con umbrales del mejor trial\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    best_dir,\n",
    "    num_labels=len(LABEL_COLUMNS),\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    id2label={i: l for i, l in enumerate(LABEL_COLUMNS)},\n",
    "    label2id={l: i for i, l in enumerate(LABEL_COLUMNS)}\n",
    ")\n",
    "\n",
    "best_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/scibert_uncased_best_final\",\n",
    "    per_device_eval_batch_size=32,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "best_trainer = Trainer(model=best_model, args=best_args, eval_dataset=test_enc)\n",
    "\n",
    "test_out = best_trainer.predict(test_enc)\n",
    "test_probs = sigmoid(test_out.predictions)\n",
    "test_y = test_out.label_ids\n",
    "test_preds_thr = (test_probs >= best_thresholds).astype(int)\n",
    "\n",
    "test_metrics = {\n",
    "    \"f1_macro\":    f1_score(test_y, test_preds_thr, average=\"macro\",    zero_division=0),\n",
    "    \"f1_micro\":    f1_score(test_y, test_preds_thr, average=\"micro\",    zero_division=0),\n",
    "    \"f1_weighted\": f1_score(test_y, test_preds_thr, average=\"weighted\", zero_division=0),\n",
    "    \"auprc_macro\": average_precision_score(test_y, test_probs, average=\"macro\")\n",
    "}\n",
    "print(\"\\n🧪 Métricas en TEST con umbrales ajustados (mejor trial):\")\n",
    "print(test_metrics)\n",
    "\n",
    "# Guardar mejor modelo, tokenizador y umbrales\n",
    "final_dir = \"/kaggle/working/scibert_uncased_hpo_best\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "best_model.save_pretrained(final_dir) # <-- Guarda el modelo\n",
    "tokenizer.save_pretrained(final_dir) # <-- AÑADIR ESTA LÍNEA para guardar el tokenizador\n",
    "\n",
    "with open(os.path.join(final_dir, \"best_thresholds.json\"), \"w\") as f:\n",
    "    json.dump({\"labels\": LABEL_COLUMNS, \"thresholds\": best_thresholds.tolist()}, f, indent=2) # <-- Guarda los umbrales\n",
    "print(f\"\\n✅ Paquete de inferencia completo guardado en: {final_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de Hiperparámetros: Resultados y Mejor Configuración\n",
    "Se llevó a cabo un proceso de optimización de hiperparámetros (HPO) para encontrar la configuración óptima del modelo SciBERT en la tarea de clasificación. Se evaluaron un total de 10 combinaciones (trials) utilizando la métrica de F1-Score Ponderado (Weighted F1-Score) sobre el conjunto de validación.\n",
    "\n",
    "Resultados Clave\n",
    "Tras el análisis de los 10 trials ejecutados, el Trial 6 emergió como el de mejor rendimiento, superando a todas las demás configuraciones evaluadas.\n",
    "\n",
    "Mejor Trial: Trial 6\n",
    "Valor de la Métrica (Weighted F1-Score): 0.9623\n",
    "Hiperparámetros del Mejor Modelo (Trial 6)\n",
    "La configuración de hiperparámetros que produjo este resultado fue la siguiente:\n",
    "\n",
    "Hiperparámetro\tValor\tDescripción\n",
    "learning_rate\t4.748e-05\tTasa de aprendizaje para el optimizador AdamW.\n",
    "effective_batch_size\t16\tTamaño de lote efectivo para el entrenamiento.\n",
    "num_train_epochs\t7\tNúmero de épocas completas de entrenamiento.\n",
    "weight_decay\t0.00956\tCoeficiente de regularización L2 para prevenir el sobreajuste.\n",
    "warmup_ratio\t0.0196\tProporción de pasos de \"calentamiento\" para la tasa de aprendizaje.\n",
    "Conclusión\n",
    "El modelo final será entrenado utilizando la configuración del Trial 6, ya que ha demostrado ser la más efectiva durante la fase de experimentación y optimización. Los archivos de este modelo servirán como base para la evaluación final en el conjunto de prueba y para el despliegue de la solución."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8133231,
     "sourceId": 12858791,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
